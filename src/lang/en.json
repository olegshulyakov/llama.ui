{
  "header.title.noChat": "New Chat",
  "header.title.settings": "Settings",
  "chatScreen": {
    "welcome": "Hi,",
    "welcomeNote": "how can I help you?"
  },
  "chatMessage": {
    "systemLabel": "System",
    "userLabel": "You"
  },
  "settings": {
    "parameters": {
      "provider": {
        "label": "Provider",
        "note": "Provider may charge for usage."
      },
      "baseUrl": {
        "label": "Base URL",
        "note": "Set the Base URL if you are using standalone server."
      },
      "apiKey": {
        "label": "API Key",
        "note": "Set the API Key if you are using --api-key option for the server."
      },
      "model": {
        "label": "Model",
        "note": "Set the inference model."
      },
      "systemMessage": {
        "label": "System Message (will be disabled if left empty)",
        "note": "The starting message that defines how model should behave. You can get examples from <a class=\"underline\" href=\"https://prompts.chat/\" target=\"_blank\" rel=\"noopener noreferrer\">Awesome ChatGPT Prompts</a>"
      },
      "initials": {
        "label": "User Name",
        "note": ""
      },
      "pasteLongTextToFileLen": {
        "label": "On Paste: convert to file if length >",
        "note": "On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Set to 0 to disable."
      },
      "pdfAsImage": {
        "label": "Use PDF as image instead of text",
        "note": "Attach PDF as image instead of text. Supported only with multimodal models with vision support."
      },
      "showTokensPerSecond": {
        "label": "Show performance metrics",
        "note": "Enable to see processing speed, timings, etc."
      },
      "showThoughtInProgress": {
        "label": "Expand thinking section",
        "note": "Expand thinking message when generating messages"
      },
      "excludeThoughtOnReq": {
        "label": "Exclude thinking messages on submit",
        "note": "Exclude thinking messages when sending requests to API (recommended)"
      },
      "overrideGenerationOptions": {
        "label": "Override Generation Options",
        "note": ""
      },
      "temperature": {
        "label": "",
        "note": "Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused."
      },
      "top_k": {
        "label": "",
        "note": "Keeps only k top tokens."
      },
      "top_p": {
        "label": "",
        "note": "Limits tokens to those that together have a cumulative probability of at least p"
      },
      "min_p": {
        "label": "",
        "note": "Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token."
      },
      "max_tokens": {
        "label": "",
        "note": "The maximum number of token per output."
      },
      "overrideSamplersOptions": {
        "label": "Override Samplers Options",
        "note": ""
      },
      "samplers": {
        "label": "Samplers queue",
        "note": "The order at which samplers are applied, in simplified way. Default is \"dkypmxt\": dry->top_k->typ_p->top_p->min_p->xtc->temperature"
      },
      "dynatemp_range": {
        "label": "",
        "note": "Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens."
      },
      "dynatemp_exponent": {
        "label": "",
        "note": "Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token."
      },
      "typical_p": {
        "label": "",
        "note": "Sorts and limits tokens based on the difference between log-probability and entropy."
      },
      "xtc_probability": {
        "label": "",
        "note": "XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC."
      },
      "xtc_threshold": {
        "label": "",
        "note": "XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token."
      },
      "overridePenaltyOptions": {
        "label": "Override Penalty Options",
        "note": ""
      },
      "repeat_last_n": {
        "label": "",
        "note": "Last n tokens to consider for penalizing repetition"
      },
      "repeat_penalty": {
        "label": "",
        "note": "Controls the repetition of token sequences in the generated text"
      },
      "presence_penalty": {
        "label": "",
        "note": "Limits tokens based on whether they appear in the output or not."
      },
      "frequency_penalty": {
        "label": "",
        "note": "Limits tokens based on how often they appear in the output."
      },
      "dry_multiplier": {
        "label": "",
        "note": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier."
      },
      "dry_base": {
        "label": "",
        "note": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value."
      },
      "dry_allowed_length": {
        "label": "",
        "note": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling."
      },
      "dry_penalty_last_n": {
        "label": "",
        "note": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens."
      },
      "custom": {
        "label": "Custom JSON config",
        "note": "For more info, refer to <a class=\"underline\" href=\"https://github.com/ggerganov/llama.cpp/blob/master/tools/server/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">server documentation</a>"
      },
      "pyIntepreterEnabled": {
        "label": "Enable Python interpreter",
        "note": "This feature uses <a class=\"underline\" href=\"https://pyodide.org\" target=\"_blank\" rel=\"noopener noreferrer\">pyodide</a>, downloaded from CDN. To use this feature, ask the LLM to generate Python code inside a Markdown code block. You will see a \"Run\" button on the code block, near the \"Copy\" button."
      },
      "ttsPitch": {
        "label": "Pitch",
        "note": "The pitch at which the utterance will be spoken at."
      },
      "ttsRate": {
        "label": "Rate",
        "note": "The speed at which the utterance will be spoken at."
      },
      "ttsVoice": {
        "label": "Voice",
        "note": "The voice that will be used to speak the utterance."
      },
      "ttsVolume": {
        "label": "Volume",
        "note": "The volume that the utterance will be spoken at."
      }
    },
    "textToSpeech": {
      "check": {
        "label": "Check",
        "text": "Hello, world!"
      }
    },
    "presetManager": {
      "newPreset": {
        "title": "Save current settings as a preset",
        "saveBtnLabel": "Save New Preset"
      },
      "savedPresets": {
        "title": "Existing presets",
        "noPresetFound": "No presets yet."
      }
    },
    "themeManager": {
      "dataTheme": {
        "label": "Theme",
        "note": "Choose the color theme for application."
      },
      "syntaxTheme": {
        "label": "Syntax Theme",
        "note": "Choose the color theme for code blocks."
      }
    },
    "actionButtons": {
      "saveBtnLabel": "Save",
      "cancelBtnLabel": "Close",
      "resetBtnLabel": "Reset"
    }
  },
  "newVersion": {
    "icon": null,
    "title": "ðŸŽ‰ New version available",
    "description": "Update for the latest features & fixes.",
    "note": "Your conversations will be saved, but don't forget to make a backup before update.",
    "submitBtnLabel": "Update",
    "cancelBtnLabel": "Later"
  },
  "welcomePopup": {
    "icon": null,
    "title": "ðŸ‘‹ Welcome",
    "description": "It looks like you don't have the models set up yet. Let's go to the Settings to configure your Inference provider.",
    "submitBtnLabel": "Open Settings",
    "cancelBtnLabel": "Skip"
  },
  "noModelsPopup": {
    "icon": null,
    "title": "ðŸ˜” No Models Found",
    "description": "It looks like you don't have the models set up yet or there is an issue with your Provider. Let's go to the Settings to check.",
    "submitBtnLabel": "Open Settings",
    "cancelBtnLabel": "Skip"
  },
  "samplePrompts": [
    "Tell me a fun fact for today.",
    "Tell me a joke.",
    "Give me three interesting science facts.",
    "List the planets in our solar system.",
    "Explain the rules of chess.",
    "What are some good conversation starters?",
    "Give 10 gift ideas for best friend.",
    "Write a birthday message for my friend.",
    "Suggest themes for a birthday party.",
    "Give me ideas for a game night.",
    "Give me ideas for a weekend getaway.",
    "Tips for my first solo trip.",
    "Explain a complex concept simply.",
    "Fix the grammar in this text.",
    "Summarize the following text.",
    "Rewrite this to be more formal/casual.",
    "Help me write a professional email.",
    "Create a schedule for my workday.",
    "Summarize these meeting notes.",
    "Give me ideas for a team building activity."
  ]
}
